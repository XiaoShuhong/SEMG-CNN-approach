{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfe1d858-2b51-42c1-8ac7-c5ed14e48bbc"
      },
      "source": [
        "\n",
        "from keras.applications.xception import Xception\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Model\n",
        "import os\n",
        "from keras.preprocessing import image\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.metrics import categorical_accuracy\n",
        "from keras.callbacks import Callback, ModelCheckpoint,LearningRateScheduler,EarlyStopping,ReduceLROnPlateau\n",
        "from keras.optimizers import SGD"
      ],
      "id": "cfe1d858-2b51-42c1-8ac7-c5ed14e48bbc",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3DtmAZ4dYd8",
        "outputId": "2a9aac08-cddd-46ad-d1d9-9ade0b9552c3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "U3DtmAZ4dYd8",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsLQJZ0HdYgS"
      },
      "source": [
        "path1='/content/drive/MyDrive/srtp-xsh/RGBimg/raw_image/s1'\n",
        "s1_weight='/content/drive/MyDrive/srtp-xsh/RGBimg/raw_image/s1/s1.h5'"
      ],
      "id": "VsLQJZ0HdYgS",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fngnspJdYjA"
      },
      "source": [
        "train1=path1+'/'+os.listdir(path1)[0]\n",
        "test1=path1+'/'+os.listdir(path1)[1]\n",
        "X_1_train=[]\n",
        "Y_1_train=[]\n",
        "for x in os.listdir(train1):\n",
        "\n",
        "  f=train1+'/'+x\n",
        "  img=image.load_img(f)\n",
        "  img=image.img_to_array(img)\n",
        "  img=image.smart_resize(img, (100,200), interpolation='bilinear')\n",
        "  label=x[3]\n",
        "  X_1_train.append(img)\n",
        "  Y_1_train.append(label)\n",
        "\n",
        "X_1_test=[]\n",
        "Y_1_test=[]\n",
        "for x in os.listdir(test1):\n",
        "  f=test1+'/'+x\n",
        "  img=image.load_img(f)\n",
        "  img=image.img_to_array(img)\n",
        "  img=image.smart_resize(img, (100,200), interpolation='bilinear')\n",
        "  label=x[3]\n",
        "  X_1_test.append(img)\n",
        "  Y_1_test.append(label)\n",
        "\n"
      ],
      "id": "_fngnspJdYjA",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_oNc4eGdYlg",
        "outputId": "de95caba-3ae5-4c1a-b25e-dcdc39a2b596"
      },
      "source": [
        "X_1_train=np.asarray(X_1_train,np.float32)\n",
        "X_1_test=np.asarray(X_1_test,np.float32)\n",
        "Y_1_train=np.asarray(Y_1_train,np.float32)\n",
        "Y_1_test=np.asarray(Y_1_test,np.float32)\n",
        "\n",
        "num_example=X_1_train.shape[0]\n",
        "arr=np.arange(num_example)\n",
        "np.random.shuffle(arr)\n",
        "X_1_train=X_1_train[arr]\n",
        "Y_1_train=Y_1_train[arr]\n",
        "\n",
        "if Y_1_train.shape!=(364,52):\n",
        "  Y_1_train = to_categorical(Y_1_train,num_classes=52)\n",
        "  Y_1_test = to_categorical(Y_1_test,num_classes=52)\n",
        "\n",
        "print('shape of training data:',X_1_train.shape)\n",
        "print('shape of training label:',Y_1_train.shape)\n",
        "print('shape of test data:',X_1_test.shape)\n",
        "print('shape of test label:',Y_1_test.shape)"
      ],
      "id": "y_oNc4eGdYlg",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of training data: (364, 100, 200, 3)\n",
            "shape of training label: (364, 52)\n",
            "shape of test data: (156, 100, 200, 3)\n",
            "shape of test label: (156, 52)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daRMfxL5dYpA"
      },
      "source": [
        "def minibatches(inputs=None, targets=None, batch_size=None, shuffle=False, aug=None):\n",
        "    while 1:  \n",
        "        assert len(inputs) == len(targets)\n",
        "        if shuffle:\n",
        "            indices = np.arange(len(inputs))\n",
        "            np.random.shuffle(indices)\n",
        "        for start_idx in range( len(inputs) - batch_size ):\n",
        "            if shuffle:\n",
        "                excerpt = indices[start_idx:start_idx + batch_size]\n",
        "                if aug is not None:\n",
        "                  (inputs[excerpt], targets[excerpt]) = next(aug.flow(inputs[excerpt],targets[excerpt], batch_size=batch_size))\n",
        "            else:\n",
        "                excerpt = slice(start_idx, start_idx + batch_size)\n",
        "                if aug is not None:\n",
        "                  (inputs[excerpt], targets[excerpt]) = next(aug.flow(inputs[excerpt],targets[excerpt], batch_size=batch_size))\n",
        "            yield inputs[excerpt], targets[excerpt]\n",
        "\n"
      ],
      "id": "daRMfxL5dYpA",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRB076BkzaBa"
      },
      "source": [
        ""
      ],
      "id": "hRB076BkzaBa",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxg46618i3tC"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
        "\twidth_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
        "\thorizontal_flip=True, fill_mode=\"nearest\")\n"
      ],
      "id": "uxg46618i3tC",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1UJv6saR7vM"
      },
      "source": [
        "\n",
        "base_model=Xception(include_top=False, weights='imagenet', input_tensor=None, input_shape=(100,200,3), pooling='avg')\n",
        "x=base_model.output\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(52, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "id": "-1UJv6saR7vM",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw_UfTvywJJ8"
      },
      "source": [
        "####随便跑的sgd"
      ],
      "id": "zw_UfTvywJJ8",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2YfWwD1viNP"
      },
      "source": [
        "model.compile(optimizer='SGD', loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "callbacks = [ModelCheckpoint(s1_weight, monitor='val_loss', save_best_only=True)]\n",
        "history = model.fit(X_1_train,\n",
        "                    Y_1_train,\n",
        "                    epochs=64,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=callbacks)\n"
      ],
      "id": "-2YfWwD1viNP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULupKg8RwqVF",
        "outputId": "f0a05f9a-5a3a-4d2c-9b10-151302820815"
      },
      "source": [
        "\n",
        "model.load_weights(s1_weight)\n",
        "loss, accuracy = model.evaluate(X_1_test,\n",
        "                    Y_1_test,)\n",
        "print('loss = {0:.4f}, accuracy = {1:.4f}'.format(loss, accuracy))"
      ],
      "id": "ULupKg8RwqVF",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 138ms/step - loss: 0.5077 - categorical_accuracy: 0.8333\n",
            "loss = 0.5077, accuracy = 0.8333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q6m67wx7DCh"
      },
      "source": [
        ""
      ],
      "id": "2Q6m67wx7DCh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2vn79St7DG4"
      },
      "source": [
        ""
      ],
      "id": "h2vn79St7DG4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr8aanBewJlv"
      },
      "source": [
        "####调参部分 （xsh调参自用，糟糕）"
      ],
      "id": "jr8aanBewJlv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVvRQZqTUO8G"
      },
      "source": [
        "# use this for pre-train\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "id": "TVvRQZqTUO8G",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5c2UhTeaPWM"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
      ],
      "id": "P5c2UhTeaPWM",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asH8t6O4arMp",
        "outputId": "2560fdf3-c316-44bd-de28-02efc3eaf8f4"
      },
      "source": [
        "model.summary()"
      ],
      "id": "asH8t6O4arMp",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 100, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 49, 99, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 49, 99, 32)   128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 49, 99, 32)   0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 47, 97, 64)   18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 47, 97, 64)   256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 47, 97, 64)   0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 47, 97, 128)  8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 47, 97, 128)  512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 47, 97, 128)  0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 47, 97, 128)  17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 47, 97, 128)  512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 24, 49, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 24, 49, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 24, 49, 128)  512         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 24, 49, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 24, 49, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 24, 49, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 24, 49, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 24, 49, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 24, 49, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 24, 49, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 12, 25, 256)  32768       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 12, 25, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 12, 25, 256)  1024        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 12, 25, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 12, 25, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 12, 25, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 12, 25, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 12, 25, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 12, 25, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 12, 25, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 6, 13, 728)   186368      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 6, 13, 728)   0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 6, 13, 728)   2912        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 6, 13, 728)   0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 6, 13, 728)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 6, 13, 728)   536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 6, 13, 728)   2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 6, 13, 728)   0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 6, 13, 728)   536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 6, 13, 728)   2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 6, 13, 728)   0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 6, 13, 728)   536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 6, 13, 728)   2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 6, 13, 728)   0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 6, 13, 728)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 6, 13, 728)   536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 6, 13, 728)   2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 6, 13, 728)   0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 6, 13, 728)   536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 6, 13, 728)   2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 6, 13, 728)   0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 6, 13, 728)   536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 6, 13, 728)   2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 6, 13, 728)   0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 6, 13, 728)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 6, 13, 728)   536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 6, 13, 728)   2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 6, 13, 728)   0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 6, 13, 728)   536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 6, 13, 728)   2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 6, 13, 728)   0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 6, 13, 728)   536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 6, 13, 728)   2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 6, 13, 728)   0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 6, 13, 728)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 6, 13, 728)   536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 6, 13, 728)   2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 6, 13, 728)   0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 6, 13, 728)   536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 6, 13, 728)   2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 6, 13, 728)   0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 6, 13, 728)   536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 6, 13, 728)   2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 6, 13, 728)   0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 6, 13, 728)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 6, 13, 728)   536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 6, 13, 728)   2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 6, 13, 728)   0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 6, 13, 728)   536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 6, 13, 728)   2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 6, 13, 728)   0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 6, 13, 728)   536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 6, 13, 728)   2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 6, 13, 728)   0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 6, 13, 728)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 6, 13, 728)   536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 6, 13, 728)   2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 6, 13, 728)   0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 6, 13, 728)   536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 6, 13, 728)   2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 6, 13, 728)   0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 6, 13, 728)   536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 6, 13, 728)   2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 6, 13, 728)   0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 6, 13, 728)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 6, 13, 728)   536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 6, 13, 728)   2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 6, 13, 728)   0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 6, 13, 728)   536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 6, 13, 728)   2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 6, 13, 728)   0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 6, 13, 728)   536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 6, 13, 728)   2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 6, 13, 728)   0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 6, 13, 728)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 6, 13, 728)   536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 6, 13, 728)   2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 6, 13, 728)   0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 6, 13, 728)   536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 6, 13, 728)   2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 6, 13, 728)   0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 6, 13, 728)   536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 6, 13, 728)   2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 6, 13, 728)   0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 6, 13, 728)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 6, 13, 728)   536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 6, 13, 728)   2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 6, 13, 728)   0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 6, 13, 1024)  752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 6, 13, 1024)  4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 3, 7, 1024)   745472      add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 3, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 3, 7, 1024)   4096        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 3, 7, 1024)   0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 3, 7, 1536)   1582080     add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 3, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 3, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 3, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 3, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 3, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         2098176     global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          524800      dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 52)           26676       dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,511,132\n",
            "Trainable params: 2,649,652\n",
            "Non-trainable params: 20,861,480\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt_7b5BCt5DQ"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='/content/drive/MyDrive/srtp-xsh/RGBimg/raw_image/s1/model.png',show_shapes=True)"
      ],
      "id": "yt_7b5BCt5DQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c3t76lsviPq"
      },
      "source": [
        ""
      ],
      "id": "8c3t76lsviPq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDIKcGsiviST"
      },
      "source": [
        ""
      ],
      "id": "fDIKcGsiviST",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eODmZYFMauh3",
        "outputId": "9ce3be55-6d18-404f-f9b2-e57e9cfb3f27"
      },
      "source": [
        "\n",
        "his=model.fit_generator(minibatches(X_1_train,Y_1_train,batch_size=6,shuffle=False,aug=None),\n",
        "                            steps_per_epoch=len(X_1_train)//6,\n",
        "                            callbacks = [ModelCheckpoint(s1_weight, monitor='val_loss', save_best_only=True, save_weight_only=True)],\n",
        "                            validation_data=minibatches(X_1_test,Y_1_test,batch_size=6,shuffle=True,aug=None),\n",
        "                            validation_steps=len(X_1_test)//6,\n",
        "                            epochs=6)\n"
      ],
      "id": "eODmZYFMauh3",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "60/60 [==============================] - 9s 62ms/step - loss: 7.0793 - val_loss: 3.5446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/6\n",
            "60/60 [==============================] - 3s 47ms/step - loss: 1.4183 - val_loss: 3.0826\n",
            "Epoch 3/6\n",
            "60/60 [==============================] - 3s 46ms/step - loss: 0.9366 - val_loss: 2.3535\n",
            "Epoch 4/6\n",
            "60/60 [==============================] - 3s 46ms/step - loss: 0.7330 - val_loss: 2.0755\n",
            "Epoch 5/6\n",
            "60/60 [==============================] - 3s 46ms/step - loss: 0.6831 - val_loss: 1.2911\n",
            "Epoch 6/6\n",
            "60/60 [==============================] - 3s 47ms/step - loss: 0.8389 - val_loss: 1.7305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGv4ATT_dpxV"
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# H=his\n",
        "# N = 6 # N=epochs \n",
        "# plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "# plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "# plt.title(\"Training Loss on Dataset\")\n",
        "# plt.xlabel(\"Epoch #\")\n",
        "# plt.ylabel(\"Loss\")\n",
        "# plt.legend(loc=\"lower left\")\n",
        "# plt.savefig(\"plot.png\")\n"
      ],
      "id": "QGv4ATT_dpxV",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIjI-dlQdzXg"
      },
      "source": [
        "for i, layer in enumerate(model.layers):\n",
        "   print(i, layer.name)"
      ],
      "id": "XIjI-dlQdzXg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU76xvVlwccw"
      },
      "source": [
        "# freeze and train\n",
        "# 0-35\n",
        "# (35-55\n",
        "# 55-75\n",
        "# 75-95\n",
        "# 95-115)\n",
        "# 115-132\n"
      ],
      "id": "WU76xvVlwccw",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cCp5hdSx1M7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96457d27-b695-469b-d880-9febacd2a69c"
      },
      "source": [
        "for layer in model.layers[0:115]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[115:133]:\n",
        "   layer.trainable = True\n",
        "for layer in model.layers[133:]:\n",
        "   layer.trainable = False\n",
        "model.load_weights(s1_weight)\n",
        "model.compile(optimizer=SGD(lr=0.005, momentum=0.9), loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "his=model.fit_generator(minibatches(X_1_train,Y_1_train,batch_size=20,shuffle=False,aug=None),\n",
        "                            steps_per_epoch=len(X_1_train)//20,\n",
        "                            callbacks = [ModelCheckpoint(s1_weight, monitor='val_loss', save_best_only=True, save_weight_only=True),learning_rate_reduction],\n",
        "                            validation_data=minibatches(X_1_test,Y_1_test,batch_size=6,shuffle=True,aug=None),\n",
        "                            validation_steps=len(X_1_test)//20,\n",
        "                            epochs=20)"
      ],
      "id": "9cCp5hdSx1M7",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "18/18 [==============================] - 7s 167ms/step - loss: 2.6403 - categorical_accuracy: 0.3250 - val_loss: 2.1476 - val_categorical_accuracy: 0.5952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/20\n",
            "18/18 [==============================] - 2s 118ms/step - loss: 2.2247 - categorical_accuracy: 0.2944 - val_loss: 2.2400 - val_categorical_accuracy: 0.4048\n",
            "Epoch 3/20\n",
            "18/18 [==============================] - 2s 117ms/step - loss: 2.1507 - categorical_accuracy: 0.2306 - val_loss: 2.5773 - val_categorical_accuracy: 0.1667\n",
            "Epoch 4/20\n",
            "18/18 [==============================] - 2s 117ms/step - loss: 1.7937 - categorical_accuracy: 0.4167 - val_loss: 1.7973 - val_categorical_accuracy: 0.2381\n",
            "Epoch 5/20\n",
            "18/18 [==============================] - 2s 122ms/step - loss: 1.4493 - categorical_accuracy: 0.5056 - val_loss: 1.4428 - val_categorical_accuracy: 0.4524\n",
            "Epoch 6/20\n",
            "18/18 [==============================] - 2s 118ms/step - loss: 1.7448 - categorical_accuracy: 0.3667 - val_loss: 2.1815 - val_categorical_accuracy: 0.4048\n",
            "Epoch 7/20\n",
            "18/18 [==============================] - 2s 120ms/step - loss: 1.3811 - categorical_accuracy: 0.5972 - val_loss: 1.8505 - val_categorical_accuracy: 0.2619\n",
            "Epoch 8/20\n",
            "18/18 [==============================] - 2s 118ms/step - loss: 1.4592 - categorical_accuracy: 0.5083 - val_loss: 1.7435 - val_categorical_accuracy: 0.5000\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "Epoch 9/20\n",
            "18/18 [==============================] - 2s 118ms/step - loss: 1.4262 - categorical_accuracy: 0.5361 - val_loss: 1.6702 - val_categorical_accuracy: 0.3333\n",
            "Epoch 10/20\n",
            "18/18 [==============================] - 2s 120ms/step - loss: 1.2733 - categorical_accuracy: 0.5167 - val_loss: 1.9987 - val_categorical_accuracy: 0.3333\n",
            "Epoch 11/20\n",
            "18/18 [==============================] - 2s 117ms/step - loss: 1.3946 - categorical_accuracy: 0.5056 - val_loss: 1.3486 - val_categorical_accuracy: 0.4762\n",
            "Epoch 12/20\n",
            "18/18 [==============================] - 2s 121ms/step - loss: 1.0981 - categorical_accuracy: 0.6056 - val_loss: 1.5426 - val_categorical_accuracy: 0.3333\n",
            "Epoch 13/20\n",
            "18/18 [==============================] - 2s 118ms/step - loss: 1.6116 - categorical_accuracy: 0.4333 - val_loss: 2.2726 - val_categorical_accuracy: 0.2143\n",
            "Epoch 14/20\n",
            "18/18 [==============================] - 2s 120ms/step - loss: 1.5301 - categorical_accuracy: 0.4306 - val_loss: 1.7388 - val_categorical_accuracy: 0.2857\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "Epoch 15/20\n",
            "18/18 [==============================] - 2s 118ms/step - loss: 1.2445 - categorical_accuracy: 0.5722 - val_loss: 1.4538 - val_categorical_accuracy: 0.3333\n",
            "Epoch 16/20\n",
            "18/18 [==============================] - 2s 119ms/step - loss: 1.2029 - categorical_accuracy: 0.6194 - val_loss: 1.1621 - val_categorical_accuracy: 0.5714\n",
            "Epoch 17/20\n",
            "18/18 [==============================] - 2s 119ms/step - loss: 1.6561 - categorical_accuracy: 0.4222 - val_loss: 1.4562 - val_categorical_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "18/18 [==============================] - 2s 120ms/step - loss: 1.1627 - categorical_accuracy: 0.6444 - val_loss: 1.2448 - val_categorical_accuracy: 0.4524\n",
            "Epoch 19/20\n",
            "18/18 [==============================] - 2s 119ms/step - loss: 1.3110 - categorical_accuracy: 0.6306 - val_loss: 1.2595 - val_categorical_accuracy: 0.6190\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "Epoch 20/20\n",
            "18/18 [==============================] - 2s 123ms/step - loss: 1.2333 - categorical_accuracy: 0.6139 - val_loss: 0.8843 - val_categorical_accuracy: 0.7381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwuZPizwx1K1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b632073-8bad-4386-a21f-ae0a3eb81a08"
      },
      "source": [
        "for layer in model.layers[0:95]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[95:115]:\n",
        "   layer.trainable = True\n",
        "for layer in model.layers[115:]:\n",
        "   layer.trainable = False\n",
        "model.load_weights(s1_weight)\n",
        "model.compile(optimizer=SGD(lr=0.005, momentum=0.9), loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "his=model.fit_generator(minibatches(X_1_train,Y_1_train,batch_size=20,shuffle=False,aug=None),\n",
        "                            steps_per_epoch=len(X_1_train)//20,\n",
        "                            callbacks = [ModelCheckpoint(s1_weight, monitor='val_loss', save_best_only=True, save_weight_only=True),learning_rate_reduction],\n",
        "                            validation_data=minibatches(X_1_test,Y_1_test,batch_size=6,shuffle=False,aug=None),\n",
        "                            validation_steps=len(X_1_test)//20,\n",
        "                            epochs=20)"
      ],
      "id": "KwuZPizwx1K1",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "18/18 [==============================] - 7s 203ms/step - loss: 2.5897 - categorical_accuracy: 0.2667 - val_loss: 3.1287 - val_categorical_accuracy: 0.1667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/20\n",
            "18/18 [==============================] - 3s 142ms/step - loss: 2.8033 - categorical_accuracy: 0.2083 - val_loss: 3.3179 - val_categorical_accuracy: 0.0238\n",
            "Epoch 3/20\n",
            "18/18 [==============================] - 2s 135ms/step - loss: 2.7740 - categorical_accuracy: 0.2306 - val_loss: 2.7383 - val_categorical_accuracy: 0.3333\n",
            "Epoch 4/20\n",
            "18/18 [==============================] - 2s 134ms/step - loss: 2.1264 - categorical_accuracy: 0.3833 - val_loss: 3.4429 - val_categorical_accuracy: 0.1667\n",
            "Epoch 5/20\n",
            "18/18 [==============================] - 2s 134ms/step - loss: 1.9399 - categorical_accuracy: 0.3611 - val_loss: 2.1475 - val_categorical_accuracy: 0.1429\n",
            "Epoch 6/20\n",
            "18/18 [==============================] - 2s 134ms/step - loss: 2.3470 - categorical_accuracy: 0.2028 - val_loss: 2.5495 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "18/18 [==============================] - 2s 134ms/step - loss: 2.1096 - categorical_accuracy: 0.2861 - val_loss: 2.2399 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "18/18 [==============================] - 2s 140ms/step - loss: 2.3748 - categorical_accuracy: 0.3111 - val_loss: 2.4027 - val_categorical_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "Epoch 9/20\n",
            "18/18 [==============================] - 2s 134ms/step - loss: 2.4379 - categorical_accuracy: 0.2361 - val_loss: 2.1766 - val_categorical_accuracy: 0.0952\n",
            "Epoch 10/20\n",
            "18/18 [==============================] - 2s 134ms/step - loss: 2.2866 - categorical_accuracy: 0.2917 - val_loss: 2.4169 - val_categorical_accuracy: 0.0238\n",
            "Epoch 11/20\n",
            "18/18 [==============================] - 2s 134ms/step - loss: 2.1321 - categorical_accuracy: 0.3250 - val_loss: 2.8344 - val_categorical_accuracy: 0.0952\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "Epoch 12/20\n",
            "18/18 [==============================] - 2s 135ms/step - loss: 1.7024 - categorical_accuracy: 0.4333 - val_loss: 1.4921 - val_categorical_accuracy: 0.5476\n",
            "Epoch 13/20\n",
            "18/18 [==============================] - 2s 136ms/step - loss: 2.2590 - categorical_accuracy: 0.2611 - val_loss: 1.7062 - val_categorical_accuracy: 0.4048\n",
            "Epoch 14/20\n",
            "18/18 [==============================] - 2s 136ms/step - loss: 2.3697 - categorical_accuracy: 0.2111 - val_loss: 2.1887 - val_categorical_accuracy: 0.2619\n",
            "Epoch 15/20\n",
            "18/18 [==============================] - 2s 135ms/step - loss: 2.5462 - categorical_accuracy: 0.1056 - val_loss: 1.5648 - val_categorical_accuracy: 0.5238\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "Epoch 16/20\n",
            "18/18 [==============================] - 2s 137ms/step - loss: 2.4099 - categorical_accuracy: 0.2167 - val_loss: 2.4051 - val_categorical_accuracy: 0.3810\n",
            "Epoch 17/20\n",
            "18/18 [==============================] - 2s 136ms/step - loss: 2.6486 - categorical_accuracy: 0.1972 - val_loss: 1.0667 - val_categorical_accuracy: 0.6905\n",
            "Epoch 18/20\n",
            "18/18 [==============================] - 2s 137ms/step - loss: 2.1029 - categorical_accuracy: 0.2611 - val_loss: 2.5679 - val_categorical_accuracy: 0.1905\n",
            "Epoch 19/20\n",
            "18/18 [==============================] - 2s 137ms/step - loss: 2.4947 - categorical_accuracy: 0.2778 - val_loss: 1.9753 - val_categorical_accuracy: 0.4286\n",
            "Epoch 20/20\n",
            "18/18 [==============================] - 2s 136ms/step - loss: 2.4671 - categorical_accuracy: 0.2611 - val_loss: 3.5321 - val_categorical_accuracy: 0.1190\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kahnFmO-lZft"
      },
      "source": [
        "# for layer in model.layers[0:75]:\n",
        "#    layer.trainable = False\n",
        "# for layer in model.layers[75:95]:\n",
        "#    layer.trainable = True\n",
        "# for layer in model.layers[95:]:\n",
        "#    layer.trainable = False\n",
        "# model.load_weight(s1_weight)\n",
        "# model.compile(optimizer=SGD(lr=0.005, momentum=0.9), loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "# his=model.fit_generator(minibatches(X_1_train,Y_1_train,batch_size=6,shuffle=False,aug=None),\n",
        "#                             steps_per_epoch=len(X_1_train)//6,\n",
        "#                             callbacks = [ModelCheckpoint(s1_weight, monitor='val_loss', save_best_only=True)],\n",
        "#                             validation_data=minibatches(X_1_test,Y_1_test,batch_size=6,shuffle=False,aug=None),\n",
        "#                             validation_steps=len(X_1_test)//6,\n",
        "#                             epochs=20)"
      ],
      "id": "kahnFmO-lZft",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ows0ta2Fk903"
      },
      "source": [
        "# for layer in model.layers[0:55]:\n",
        "#    layer.trainable = False\n",
        "# for layer in model.layers[55:75]:\n",
        "#    layer.trainable = True\n",
        "# for layer in model.layers[75:]:\n",
        "#    layer.trainable = False\n",
        "# model.load_weight(s1_weight)\n",
        "# model.compile(optimizer=SGD(lr=0.005, momentum=0.9), loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "# his=model.fit_generator(minibatches(X_1_train,Y_1_train,batch_size=6,shuffle=False,aug=None),\n",
        "#                             steps_per_epoch=len(X_1_train)//6,\n",
        "#                             callbacks = [ModelCheckpoint(s1_weight, monitor='val_loss', save_best_only=True)],\n",
        "#                             validation_data=minibatches(X_1_test,Y_1_test,batch_size=6,shuffle=False,aug=None),\n",
        "#                             validation_steps=len(X_1_test)//6,\n",
        "#                             epochs=20)"
      ],
      "id": "ows0ta2Fk903",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dUhqiBCiO-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f17c5070-0069-4c3c-ce12-e976efd80eca"
      },
      "source": [
        "for layer in model.layers[0:35]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[35:115]:\n",
        "   layer.trainable = True\n",
        "for layer in model.layers[55:]:\n",
        "   layer.trainable = False\n",
        "model.load_weights(s1_weight)\n",
        "model.compile(optimizer=SGD(lr=0.005, momentum=0.9), loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "his=model.fit_generator(minibatches(X_1_train,Y_1_train,batch_size=20,shuffle=False,aug=None),\n",
        "                            steps_per_epoch=len(X_1_train)//20,\n",
        "                            callbacks = [ModelCheckpoint(s1_weight, monitor='val_loss', save_best_only=True, save_weight_only=True),learning_rate_reduction],\n",
        "                            validation_data=minibatches(X_1_test,Y_1_test,batch_size=6,shuffle=False,aug=None),\n",
        "                            validation_steps=len(X_1_test)//20,\n",
        "                            epochs=20)"
      ],
      "id": "3dUhqiBCiO-S",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "18/18 [==============================] - 7s 240ms/step - loss: 3.2068 - categorical_accuracy: 0.1556 - val_loss: 3.2257 - val_categorical_accuracy: 0.1429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/20\n",
            "18/18 [==============================] - 3s 183ms/step - loss: 3.2214 - categorical_accuracy: 0.1722 - val_loss: 3.5023 - val_categorical_accuracy: 0.0238\n",
            "Epoch 3/20\n",
            "18/18 [==============================] - 3s 184ms/step - loss: 3.2206 - categorical_accuracy: 0.2167 - val_loss: 3.1862 - val_categorical_accuracy: 0.1905\n",
            "Epoch 4/20\n",
            "18/18 [==============================] - 3s 182ms/step - loss: 3.3130 - categorical_accuracy: 0.1333 - val_loss: 3.4025 - val_categorical_accuracy: 0.0238\n",
            "Epoch 5/20\n",
            "18/18 [==============================] - 3s 182ms/step - loss: 3.2457 - categorical_accuracy: 0.1139 - val_loss: 3.2438 - val_categorical_accuracy: 0.1190\n",
            "Epoch 6/20\n",
            "18/18 [==============================] - 3s 184ms/step - loss: 3.3282 - categorical_accuracy: 0.0722 - val_loss: 3.1260 - val_categorical_accuracy: 0.1190\n",
            "Epoch 7/20\n",
            "18/18 [==============================] - 3s 184ms/step - loss: 3.0099 - categorical_accuracy: 0.3472 - val_loss: 3.2881 - val_categorical_accuracy: 0.1905\n",
            "Epoch 8/20\n",
            "18/18 [==============================] - 3s 186ms/step - loss: 3.1616 - categorical_accuracy: 0.2667 - val_loss: 3.0335 - val_categorical_accuracy: 0.3333\n",
            "Epoch 9/20\n",
            "18/18 [==============================] - 3s 185ms/step - loss: 3.1812 - categorical_accuracy: 0.1972 - val_loss: 3.0297 - val_categorical_accuracy: 0.0952\n",
            "Epoch 10/20\n",
            "18/18 [==============================] - 3s 186ms/step - loss: 3.1662 - categorical_accuracy: 0.1361 - val_loss: 3.1628 - val_categorical_accuracy: 0.0476\n",
            "Epoch 11/20\n",
            "18/18 [==============================] - 3s 184ms/step - loss: 3.2747 - categorical_accuracy: 0.0306 - val_loss: 3.1992 - val_categorical_accuracy: 0.2857\n",
            "Epoch 12/20\n",
            "18/18 [==============================] - 3s 187ms/step - loss: 3.2774 - categorical_accuracy: 0.0417 - val_loss: 3.3203 - val_categorical_accuracy: 0.1905\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "Epoch 13/20\n",
            "18/18 [==============================] - 3s 185ms/step - loss: 3.3522 - categorical_accuracy: 0.1000 - val_loss: 3.2834 - val_categorical_accuracy: 0.3095\n",
            "Epoch 14/20\n",
            "18/18 [==============================] - 3s 186ms/step - loss: 3.2356 - categorical_accuracy: 0.1444 - val_loss: 3.5320 - val_categorical_accuracy: 0.0238\n",
            "Epoch 15/20\n",
            "18/18 [==============================] - 3s 186ms/step - loss: 3.2291 - categorical_accuracy: 0.1028 - val_loss: 3.1193 - val_categorical_accuracy: 0.2619\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "Epoch 16/20\n",
            "18/18 [==============================] - 3s 184ms/step - loss: 3.2089 - categorical_accuracy: 0.0972 - val_loss: 3.0100 - val_categorical_accuracy: 0.3095\n",
            "Epoch 17/20\n",
            "18/18 [==============================] - 3s 185ms/step - loss: 3.3912 - categorical_accuracy: 0.0639 - val_loss: 3.1709 - val_categorical_accuracy: 0.0714\n",
            "Epoch 18/20\n",
            "18/18 [==============================] - 3s 183ms/step - loss: 3.1190 - categorical_accuracy: 0.0861 - val_loss: 3.5731 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "18/18 [==============================] - 3s 184ms/step - loss: 3.0473 - categorical_accuracy: 0.2056 - val_loss: 3.2407 - val_categorical_accuracy: 0.3333\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "Epoch 20/20\n",
            "18/18 [==============================] - 3s 184ms/step - loss: 3.1757 - categorical_accuracy: 0.1528 - val_loss: 3.2321 - val_categorical_accuracy: 0.0952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5LATwEsbbJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "034f9db4-5620-41a3-9c88-26f406954990"
      },
      "source": [
        "for layer in model.layers[35:]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[0:35]:\n",
        "   layer.trainable = True\n",
        "model.load_weights(s1_weight)\n",
        "model.compile(optimizer=SGD(lr=0.005, momentum=0.9), loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "his=model.fit_generator(minibatches(X_1_train,Y_1_train,batch_size=20,shuffle=False,aug=None),\n",
        "                            steps_per_epoch=len(X_1_train)//20,\n",
        "                            callbacks = [ModelCheckpoint(s1_weight, monitor='val_loss', save_best_only=True, save_weight_only=True),learning_rate_reduction],\n",
        "                            validation_data=minibatches(X_1_test,Y_1_test,batch_size=6,shuffle=False,aug=None),\n",
        "                            validation_steps=len(X_1_test)//20,\n",
        "                            epochs=20)\n"
      ],
      "id": "E5LATwEsbbJ1",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "18/18 [==============================] - 11s 362ms/step - loss: 3.4386 - categorical_accuracy: 0.1944 - val_loss: 3.4923 - val_categorical_accuracy: 0.1429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/20\n",
            "18/18 [==============================] - 5s 299ms/step - loss: 3.4547 - categorical_accuracy: 0.2250 - val_loss: 3.5730 - val_categorical_accuracy: 0.0238\n",
            "Epoch 3/20\n",
            "18/18 [==============================] - 5s 303ms/step - loss: 3.4686 - categorical_accuracy: 0.1194 - val_loss: 3.4836 - val_categorical_accuracy: 0.1905\n",
            "Epoch 4/20\n",
            "18/18 [==============================] - 5s 302ms/step - loss: 3.4861 - categorical_accuracy: 0.0444 - val_loss: 3.5306 - val_categorical_accuracy: 0.0238\n",
            "Epoch 5/20\n",
            "18/18 [==============================] - 5s 305ms/step - loss: 3.4444 - categorical_accuracy: 0.1444 - val_loss: 3.3575 - val_categorical_accuracy: 0.4286\n",
            "Epoch 6/20\n",
            "18/18 [==============================] - 5s 298ms/step - loss: 3.4563 - categorical_accuracy: 0.2194 - val_loss: 3.2914 - val_categorical_accuracy: 0.6190\n",
            "Epoch 7/20\n",
            "18/18 [==============================] - 5s 299ms/step - loss: 3.4049 - categorical_accuracy: 0.3833 - val_loss: 3.3332 - val_categorical_accuracy: 0.2619\n",
            "Epoch 8/20\n",
            "18/18 [==============================] - 5s 299ms/step - loss: 3.4637 - categorical_accuracy: 0.2278 - val_loss: 3.2672 - val_categorical_accuracy: 0.7381\n",
            "Epoch 9/20\n",
            "18/18 [==============================] - 5s 298ms/step - loss: 3.4066 - categorical_accuracy: 0.2528 - val_loss: 3.2695 - val_categorical_accuracy: 0.7143\n",
            "Epoch 10/20\n",
            "18/18 [==============================] - 5s 300ms/step - loss: 3.3960 - categorical_accuracy: 0.2889 - val_loss: 3.2863 - val_categorical_accuracy: 0.5476\n",
            "Epoch 11/20\n",
            "18/18 [==============================] - 5s 298ms/step - loss: 3.4559 - categorical_accuracy: 0.1417 - val_loss: 3.3619 - val_categorical_accuracy: 0.4524\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "Epoch 12/20\n",
            "18/18 [==============================] - 5s 297ms/step - loss: 3.4322 - categorical_accuracy: 0.1583 - val_loss: 3.4935 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "18/18 [==============================] - 5s 298ms/step - loss: 3.4663 - categorical_accuracy: 0.1750 - val_loss: 3.4962 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "18/18 [==============================] - 5s 297ms/step - loss: 3.4349 - categorical_accuracy: 0.2111 - val_loss: 3.5356 - val_categorical_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "Epoch 15/20\n",
            "18/18 [==============================] - 5s 298ms/step - loss: 3.3739 - categorical_accuracy: 0.3111 - val_loss: 3.4894 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "18/18 [==============================] - 5s 296ms/step - loss: 3.4055 - categorical_accuracy: 0.2667 - val_loss: 3.4926 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "18/18 [==============================] - 5s 299ms/step - loss: 3.5047 - categorical_accuracy: 0.0694 - val_loss: 3.4846 - val_categorical_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "Epoch 18/20\n",
            "18/18 [==============================] - 5s 296ms/step - loss: 3.4029 - categorical_accuracy: 0.3194 - val_loss: 3.5471 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "18/18 [==============================] - 5s 297ms/step - loss: 3.4182 - categorical_accuracy: 0.2944 - val_loss: 3.4937 - val_categorical_accuracy: 0.0238\n",
            "Epoch 20/20\n",
            "18/18 [==============================] - 5s 296ms/step - loss: 3.4107 - categorical_accuracy: 0.1972 - val_loss: 3.4951 - val_categorical_accuracy: 0.0952\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnZxtl-PylhB"
      },
      "source": [
        ""
      ],
      "id": "XnZxtl-PylhB",
      "execution_count": 22,
      "outputs": []
    }
  ]
}